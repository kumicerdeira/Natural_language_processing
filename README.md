This time I extracted data analysis sentences from the Japanese version of Wikipedia and analyzed them.
I used spaCy, a Python natural language processing library, to extract named entities. This is a technology that can be used primarily for chat bots and personal information protection.

I also performed analysis using MeCab, a morphological analysis engine, created a machine learning model, calculated the TF-IDF value of the data, and visualized it using a word cloud.

今回、日本語版ウィキペディアからデータ解析の文章を抽出し、分析。
Pythonの自然言語処理ライブラリであるspaCyを使い、固有表現を抽出。
主にチャットbotや個人情報保護に使用できる技術である。

また、形態素解析エンジンであるMeCabを使った分析を行い、機械学習モデルを作成し、データのTF-IDF値を求めワードクラウドを使って視覚化を行いました。
